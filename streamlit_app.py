import streamlit as st
import pandas as pd
import numpy as np
import torch
import pickle
import altair as alt
from pytorch_forecasting import TemporalFusionTransformer
import os
from sklearn.metrics import mean_absolute_error, mean_squared_error
import math
import copy

# -----------------------------
# App config
# -----------------------------
st.set_page_config(layout="wide", page_title="InnovateMart Forecast Viewer")
st.title("InnovateMart โ ูุดุงูุฏูู ูพุดโุจูโูุง TFT")

# -----------------------------
# I/O utilities
# -----------------------------
@st.cache_resource
def load_pickles(model_dir="models"):
    paths = {
        "training_ds": os.path.join(model_dir, "training_dataset.pkl"),
        "validation_ds": os.path.join(model_dir, "validation_dataset.pkl"),
        "validation_raw": os.path.join(model_dir, "validation_raw.pkl"),
        "ckpt": os.path.join(model_dir, "tft_ckpt.pth"),
    }
    for k, p in paths.items():
        if not os.path.exists(p):
            st.error(f"ูุงู ูพุฏุง ูุดุฏ: {p}")
    with open(paths["training_ds"], "rb") as f:
        training = pickle.load(f)
    with open(paths["validation_ds"], "rb") as f:
        validation = pickle.load(f)
    with open(paths["validation_raw"], "rb") as f:
        val_raw = pickle.load(f)
    ckpt_path = paths["ckpt"]
    return training, validation, val_raw, ckpt_path

# -----------------------------
# Model build / load
# -----------------------------
from pytorch_forecasting.metrics import QuantileLoss

@st.cache_resource
def build_and_load_model(_training_ds, ckpt_path, device="cpu"):
    tft = TemporalFusionTransformer.from_dataset(
        _training_ds,
        learning_rate=1e-3,
        hidden_size=16,
        attention_head_size=1,
        dropout=0.1,
        hidden_continuous_size=8,
        log_interval=10,
        reduce_on_plateau_patience=2,
        loss=QuantileLoss(quantiles=[0.5]),
    )
    state = torch.load(ckpt_path, map_location=device)
    if isinstance(state, dict) and "state_dict" in state:
        state = state["state_dict"]
    tft.load_state_dict(state)
    tft.to(device)
    tft.eval()
    return tft

# -----------------------------
# Prediction helpers
# -----------------------------

def predict_on_validation(tft, validation_ds, batch_size=64, device="cpu"):
    val_dl = validation_ds.to_dataloader(train=False, batch_size=batch_size, num_workers=0)
    preds = tft.predict(val_dl)
    return preds


def map_preds_to_dates_fixed(preds, validation_raw, validation_ds):
    """
    ูฺฏุงุดุช ูพุดโุจูโูุง ุจู ูุฑูุดฺฏุงูโูุง ู ุชุงุฑุฎโูุง (ุจุฑุง ููู ูุฑูุดฺฏุงูโูุง)
    """
    rows = []
    stores = validation_raw["store_id"].unique()
    horizon = preds.shape[1]

    for i, store in enumerate(stores):
        store_min_time = validation_raw.loc[validation_raw["store_id"] == store, "time_idx"].max() - horizon + 1
        for h in range(horizon):
            time_idx = store_min_time + h
            rows.append({
                "store_id": store,
                "time_idx": time_idx,
                "pred": float(preds[i, h]),
                "horizon_step": h
            })

    pred_df = pd.DataFrame(rows)
    time_to_date = validation_raw[["time_idx", "date"]].drop_duplicates()
    pred_df = pred_df.merge(time_to_date, on="time_idx", how="left")

    actuals = validation_raw[["store_id", "time_idx", "date", "daily_sales"]].drop_duplicates()
    merged = pred_df.merge(actuals, on=["store_id", "time_idx"], how="left", suffixes=("", "_actual"))
    merged["date"] = merged["date_actual"].fillna(merged["date"])
    merged = merged.drop(columns=["date_actual"], errors="ignore")
    return merged

# -----------------------------
# Plotting utilities
# -----------------------------

def plot_store_comparison(merged_df, store=None, aggregate=False):
    if aggregate:
        df_plot = merged_df.groupby("date").agg(
            actual=("daily_sales", "sum"),
            pred=("pred", "sum")
        ).reset_index()
        title_suffix = "(ุชุฌูุน - ููู ูุฑูุดฺฏุงูโูุง)"
    else:
        if store is None:
            available_stores = merged_df["store_id"].unique()
            if len(available_stores) > 0:
                store = available_stores[0]
            else:
                st.warning("ูฺ ูุฑูุดฺฏุงู ุฏุฑ ุฏุงุฏูโูุง ุงูุช ูุดุฏ!")
                return

        store_data = merged_df[merged_df["store_id"] == store]
        if store_data.empty:
            st.warning(f"ุฏุงุฏูโุง ุจุฑุง ูุฑูุดฺฏุงู {store} ุงูุช ูุดุฏ!")
            return

        df_plot = store_data.groupby("date").agg(
            actual=("daily_sales", "mean"),
            pred=("pred", "mean")
        ).reset_index()
        title_suffix = f"(ูุฑูุดฺฏุงู {store})"

    if df_plot.empty:
        st.warning(f"ุฏุงุฏูโุง ุจุฑุง ููุงุด ุงูุช ูุดุฏ {title_suffix}")
        return

    has_actual = not df_plot['actual'].isna().all()

    if has_actual:
        df_long = df_plot.melt(id_vars=["date"], value_vars=["actual", "pred"],
                              var_name="kind", value_name="sales")
        color_scale = alt.Scale(domain=['actual', 'pred'], range=['#1f77b4', '#ff7f0e'])
        chart = alt.Chart(df_long).mark_line(point=True, strokeWidth=2).encode(
            x=alt.X("date:T", title="ุชุงุฑุฎ"),
            y=alt.Y("sales:Q", title="ูุฑูุด"),
            color=alt.Color("kind:N", title="ููุน", scale=color_scale),
            tooltip=["date:T", "kind:N", "sales:Q"]
        ).properties(width=900, height=400, title=f"ููุงุณู ูุฑูุด ูุงูุน ู ูพุดโุจู {title_suffix}")
    else:
        chart = alt.Chart(df_plot).mark_line(point=True, strokeWidth=2).encode(
            x=alt.X("date:T", title="ุชุงุฑุฎ"),
            y=alt.Y("pred:Q", title="ูุฑูุด ูพุดโุจู ุดุฏู"),
            tooltip=["date:T", "pred:Q"]
        ).properties(width=900, height=400, title=f"ูพุดโุจู ูุฑูุด {title_suffix}")

    st.altair_chart(chart, use_container_width=True)

# -----------------------------
# Permutation feature importance (robust)
# -----------------------------

def permute_feature_in_batch(x, feature_name, encoder_vars, decoder_vars):
    """
    permute ฺฉุฑุฏู ฺฉ ูฺฺฏ ุฏุฑ x (ููุท xุ ูู ฺฉู batch).
    ุฎุฑูุฌ ููุงู ููุน ูุฑูุฏ ุฑุง ุฏุงุฑุฏ.
    """
    if x is None:
        return x

    def _shuffle_along_batch(tensor):
        if not torch.is_tensor(tensor) or tensor.shape[0] <= 1:
            return tensor
        idx = torch.randperm(tensor.shape[0], device=tensor.device)
        return tensor[idx].clone()

    # dict (ุฑุงุฌโุชุฑู ุญุงูุช ุจุฑุง pytorch-forecasting)
    if isinstance(x, dict):
        x_copy = {}
        if feature_name in encoder_vars:
            feature_idx = encoder_vars.index(feature_name)
            section = "encoder"
        elif feature_name in decoder_vars:
            feature_idx = decoder_vars.index(feature_name)
            section = "decoder"
        else:
            return {k: (v.clone() if torch.is_tensor(v) else v) for k, v in x.items()}

        # continuous
        if section == "encoder" and "encoder_cont" in x and torch.is_tensor(x["encoder_cont"]):
            ec = x["encoder_cont"].clone()
            if ec.ndim >= 3 and feature_idx < ec.shape[-1]:
                vals = ec[:, :, feature_idx]
                perm_idx = torch.randperm(vals.shape[0], device=vals.device)
                ec[:, :, feature_idx] = vals[perm_idx]
                x_copy.update(x)
                x_copy["encoder_cont"] = ec
                return x_copy

        if section == "decoder" and "decoder_cont" in x and torch.is_tensor(x["decoder_cont"]):
            dc = x["decoder_cont"].clone()
            if dc.ndim >= 3 and feature_idx < dc.shape[-1]:
                vals = dc[:, :, feature_idx]
                perm_idx = torch.randperm(vals.shape[0], device=vals.device)
                dc[:, :, feature_idx] = vals[perm_idx]
                x_copy.update(x)
                x_copy["decoder_cont"] = dc
                return x_copy

        # categorical
        if section == "encoder" and "encoder_cat" in x and torch.is_tensor(x["encoder_cat"]):
            ec = x["encoder_cat"].clone()
            if ec.ndim >= 3 and feature_idx < ec.shape[-1]:
                vals = ec[:, :, feature_idx]
                perm_idx = torch.randperm(vals.shape[0], device=vals.device)
                ec[:, :, feature_idx] = vals[perm_idx]
                x_copy.update(x)
                x_copy["encoder_cat"] = ec
                return x_copy

        if section == "decoder" and "decoder_cat" in x and torch.is_tensor(x["decoder_cat"]):
            dc = x["decoder_cat"].clone()
            if dc.ndim >= 3 and feature_idx < dc.shape[-1]:
                vals = dc[:, :, feature_idx]
                perm_idx = torch.randperm(vals.shape[0], device=vals.device)
                dc[:, :, feature_idx] = vals[perm_idx]
                x_copy.update(x)
                x_copy["decoder_cat"] = dc
                return x_copy

        # fallback ุชูุงุด ุจุฑุง permute ุฏุฑ ูุฑ tensor ฺฉู ุขุฎุฑู ุจุนุฏุด >= feature_idx
        x_copy.update(x)
        for k, v in x.items():
            if torch.is_tensor(v) and v.ndim >= 1 and v.shape[-1] > feature_idx:
                try:
                    v_new = v.clone()
                    vals = v_new[..., feature_idx]
                    perm_idx = torch.randperm(vals.shape[0], device=vals.device)
                    v_new[..., feature_idx] = vals[perm_idx]
                    x_copy[k] = v_new
                    return x_copy
                except Exception:
                    continue

        return {k: (v.clone() if torch.is_tensor(v) else v) for k, v in x.items()}

    # tuple (ูุซูุงู (encoder, decoder)) โ ูพุฑุฏุงุฒุด ูุฑ ูุณูุช
    if isinstance(x, tuple):
        out_parts = []
        for part in x:
            if isinstance(part, dict):
                out_parts.append(permute_feature_in_batch(part, feature_name, encoder_vars, decoder_vars))
            elif torch.is_tensor(part):
                out_parts.append(_shuffle_along_batch(part))
            else:
                out_parts.append(part)
        return tuple(out_parts)

    # tensor ุณุงุฏู
    if torch.is_tensor(x):
        return _shuffle_along_batch(x)

    return x


def calculate_permutation_importance(tft, validation_ds, device="cpu", n_repeats=3):
    """
    ูุญุงุณุจู ุงููุช ูฺฺฏโูุง ุจุง ุฑูุด permutation (ูุณุฎู ูฺฉุณ ุดุฏู)
    """
    val_dl = validation_ds.to_dataloader(train=False, batch_size=32, num_workers=0)

    # baseline predictions
    baseline_predictions = tft.predict(val_dl)

    # ุฏุฑุงูุช actual values
    actuals = []
    for batch in val_dl:
        if isinstance(batch, tuple) and len(batch) >= 2:
            y = batch[1]
            if isinstance(y, tuple):
                y = y[0]
            if torch.is_tensor(y):
                actuals.append(y.detach().cpu().numpy())
        elif hasattr(batch, "y") and torch.is_tensor(batch.y):
            actuals.append(batch.y.detach().cpu().numpy())

    if actuals:
        actuals = np.concatenate(actuals, axis=0)
        baseline_mse = mean_squared_error(actuals.flatten(), baseline_predictions.flatten())
    else:
        baseline_mse = np.var(baseline_predictions.flatten())
        st.info("โ๏ธ actual values ูพุฏุง ูุดุฏ โ ุงุฒ variance predictions ุงุณุชูุงุฏู ุดุฏ.")

    encoder_vars = getattr(tft, "encoder_variables", []) or []
    decoder_vars = getattr(tft, "decoder_variables", []) or []
    all_features = list(dict.fromkeys(encoder_vars + decoder_vars))

    importance_scores = {}
    progress_bar = st.progress(0)
    status_text = st.empty()

    for idx, feature in enumerate(all_features):
        status_text.text(f"ุฏุฑ ุญุงู ูุญุงุณุจู ุงููุช {feature}...")
        feature_scores = []

        for repeat in range(n_repeats):
            val_dl_permuted = validation_ds.to_dataloader(train=False, batch_size=32, num_workers=0)
            permuted_predictions = []

            for batch in val_dl_permuted:
                if isinstance(batch, tuple) and len(batch) >= 2:
                    x, y = batch[0], batch[1]
                else:
                    x, y = batch, None

                # ููุท x ุฑู permute ูโฺฉูู
                x_permuted = permute_feature_in_batch(x, feature, encoder_vars, decoder_vars)

                with torch.no_grad():
                    # ูุฏู ููุดู ุงูุชุธุงุฑ dict ุฏุงุฑู โ ุงฺฏุฑ tuple ุดุฏุ ุงููู ุนุถู dict ุฑุง ุงูุชุญุงู ฺฉู
                    if isinstance(x_permuted, tuple):
                        x_input = x_permuted[0] if isinstance(x_permuted[0], dict) else x_permuted
                    else:
                        x_input = x_permuted

                    pred = tft(x_input)

                    if isinstance(pred, dict):
                        pred = pred.get("prediction", next(iter(pred.values())))
                    if isinstance(pred, (list, tuple)):
                        pred = pred[0]
                    if torch.is_tensor(pred):
                        permuted_predictions.append(pred.detach().cpu().numpy())
                    else:
                        permuted_predictions.append(np.asarray(pred))

            if len(permuted_predictions) == 0:
                continue

            permuted_predictions = np.concatenate(permuted_predictions, axis=0)

            if actuals is not None and len(actuals) > 0:
                permuted_mse = mean_squared_error(actuals.flatten(), permuted_predictions.flatten())
            else:
                permuted_mse = np.var(permuted_predictions.flatten())

            feature_scores.append(permuted_mse - baseline_mse)

        importance_scores[feature] = float(np.mean(feature_scores)) if feature_scores else 0.0
        progress_bar.progress((idx + 1) / max(1, len(all_features)))

    progress_bar.empty()
    status_text.empty()
    return importance_scores

# -----------------------------
# Session state initialization
# -----------------------------
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.available_stores = []

# -----------------------------
# Sidebar / UI controls
# -----------------------------
st.sidebar.header("ุชูุธูุงุช")
model_dir = st.sidebar.text_input("ูุณุฑ ูพูุดูู ูุฏู", value="models")
device_opt = st.sidebar.selectbox("Device", ["cpu", "cuda" if torch.cuda.is_available() else "cpu"])
batch_size = st.sidebar.slider("Batch size ุจุฑุง ูพุดโุจู", min_value=16, max_value=256, value=64, step=16)

display_mode = st.sidebar.radio(
    "ููุน ููุงุด",
    ["ุชุฌูุน (ููู ูุฑูุดฺฏุงูโูุง)", "ูุฑูุดฺฏุงู ุฎุงุต"],
    index=0
)

aggregate = display_mode == "ุชุฌูุน (ููู ูุฑูุดฺฏุงูโูุง)"

selected_store = None
if not aggregate and st.session_state.data_loaded:
    selected_store = st.sidebar.selectbox(
        "ุงูุชุฎุงุจ ูุฑูุดฺฏุงู",
        options=st.session_state.available_stores,
        index=0 if st.session_state.available_stores else None
    )

# -----------------------------
# Main flow: load, predict, show
# -----------------------------
if st.button("ุจุงุฑฺฏุฐุงุฑ ูุฏู ู ุงุฌุฑุง"):
    with st.spinner("ุฏุฑ ุญุงู ุจุงุฑฺฏุฐุงุฑ ูุงูโูุง ู ูุฏู..."):
        try:
            training_ds, validation_ds, validation_raw, ckpt_path = load_pickles(model_dir)

            # debug info
            st.write("### ุงุทูุงุนุงุช ุฏุจุงฺฏ")
            st.write(f"ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง validation_raw: {len(validation_raw)}")
            st.write(f"ูุฑูุดฺฏุงูโูุง ููุฌูุฏ: {validation_raw['store_id'].unique()}")
            st.write(f"ุจุงุฒู time_idx: {validation_raw['time_idx'].min()} ุชุง {validation_raw['time_idx'].max()}")
            st.write(f"ุจุงุฒู ุชุงุฑุฎ: {validation_raw['date'].min()} ุชุง {validation_raw['date'].max()}")

            st.session_state.available_stores = sorted(validation_raw["store_id"].unique().tolist())
            st.session_state.data_loaded = True

            tft = build_and_load_model(training_ds, ckpt_path, device=device_opt)
            st.success("ูุฏู ุจุงุฑฺฏุฐุงุฑ ุดุฏ.")

            preds = predict_on_validation(tft, validation_ds, batch_size=batch_size, device=device_opt)
            st.write("ุดฺฉู ูพุดโุจูโูุง:", preds.shape)

            merged = map_preds_to_dates_fixed(preds, validation_raw, validation_ds)

            if merged.empty:
                st.error("ูุชุฌูู ูฺฏุงุดุช ุฎุงู ุดุฏ!")
            else:
                st.write(f"ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ูฺฏุงุดุช ุงูุชู: {len(merged)}")
                st.write("ููููู ุงุฒ ุฏุงุฏูโูุง ูฺฏุงุดุช ุงูุชู:")
                st.dataframe(merged.head(10))

                st.session_state.merged_data = merged
                st.session_state.tft_model = tft
                st.session_state.validation_ds = validation_ds

                # metrics + plots
                if aggregate:
                    df_eval = merged.groupby("date").agg(actual=("daily_sales", "sum"), pred=("pred", "sum")).dropna(subset=['actual'])
                    if not df_eval.empty:
                        y_true = df_eval["actual"].values
                        y_pred = df_eval["pred"].values
                        mae_val = mean_absolute_error(y_true, y_pred)
                        rmse_val = math.sqrt(mean_squared_error(y_true, y_pred))
                        col1, col2 = st.columns(2)
                        col1.metric("MAE (ุชุฌูุน)", f"{mae_val:.3f}")
                        col2.metric("RMSE (ุชุฌูุน)", f"{rmse_val:.3f}")
                    else:
                        st.info("ุฏุงุฏู ูุงูุน ุจุฑุง ูุญุงุณุจู ูุชุฑฺฉโูุง ููุฌูุฏ ูุณุช.")
                    st.markdown("### ูููุฏุงุฑ ูุงูุน vs ูพุดโุจู (ุชุฌูุน)")
                    plot_store_comparison(merged, aggregate=True)
                else:
                    if selected_store is None and st.session_state.available_stores:
                        selected_store = st.session_state.available_stores[0]
                        st.info(f"ูุฑูุดฺฏุงู {selected_store} ุจู ุทูุฑ ุฎูุฏฺฉุงุฑ ุงูุชุฎุงุจ ุดุฏ.")

                    if selected_store is not None:
                        st.markdown(f"### ูุชุงุฌ ูุฑูุดฺฏุงู {selected_store}")
                        store_data = merged[merged["store_id"] == selected_store]
                        if store_data.empty:
                            st.error(f"ูฺ ุฏุงุฏูโุง ุจุฑุง ูุฑูุดฺฏุงู {selected_store} ุงูุช ูุดุฏ!")
                        else:
                            st.write(f"ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ูุฑูุดฺฏุงู {selected_store}: {len(store_data)}")
                            df_eval = store_data.dropna(subset=['daily_sales'])
                            if not df_eval.empty:
                                y_true = df_eval["daily_sales"].values
                                y_pred = df_eval["pred"].values
                                mae_val = mean_absolute_error(y_true, y_pred)
                                rmse_val = math.sqrt(mean_squared_error(y_true, y_pred))
                                col1, col2 = st.columns(2)
                                col1.metric(f"MAE (ูุฑูุดฺฏุงู {selected_store})", f"{mae_val:.3f}")
                                col2.metric(f"RMSE (ูุฑูุดฺฏุงู {selected_store})", f"{rmse_val:.3f}")
                            else:
                                st.info(f"ุฏุงุฏู ูุงูุน ุจุฑุง ูุฑูุดฺฏุงู {selected_store} ููุฌูุฏ ูุณุช.")

                            plot_store_comparison(merged, store=selected_store, aggregate=False)
                    else:
                        st.warning("ูฺ ูุฑูุดฺฏุงู ุจุฑุง ุงูุชุฎุงุจ ููุฌูุฏ ูุณุช.")

                # summary
                st.markdown("### ุขูุงุฑ ฺฉู")
                col1, col2, col3 = st.columns(3)
                col1.metric("ุชุนุฏุงุฏ ูุฑูุดฺฏุงูโูุง", len(merged["store_id"].unique()))
                col2.metric("ุชุนุฏุงุฏ ุฑูุฒูุง ูพุดโุจู", len(merged["date"].unique()))
                col3.metric("ุชุนุฏุงุฏ ฺฉู ุฑฺฉูุฑุฏูุง ูพุดโุจู", len(merged))

                st.markdown("### ุฎูุงุตู ูพุดโุจูโูุง ุจุฑุง ูุฑ ูุฑูุดฺฏุงู")
                summary = merged.groupby('store_id').agg({
                    'pred': ['count', 'mean', 'std'],
                    'daily_sales': ['count', 'mean', 'std']
                }).round(2)
                summary.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in summary.columns]
                st.dataframe(summary)

        except Exception as e:
            st.error(f"ุฎุทุง ุฏุฑ ุงุฌุฑุง ุจุฑูุงูู: {str(e)}")
            st.exception(e)

# -----------------------------
# Feature importance UI
# -----------------------------
if st.session_state.data_loaded:
    st.markdown("---")
    st.markdown("## ุงููุช ูฺฺฏโูุง")
    tab1, tab2 = st.tabs(["ุฑูุด ฺฉูุงุณฺฉ TFT", "ุฑูุด Permutation"])

    with tab1:
        st.markdown("### ุฑูุด ฺฉูุงุณฺฉ TFT (interpret_output)")
        if st.button("ูุญุงุณุจู ุงููุช ูฺฺฏโูุง (ฺฉูุงุณฺฉ)"):
            with st.spinner("ุฏุฑ ุญุงู ูุญุงุณุจู ุงููุช ูฺฺฏโูุง..."):
                try:
                    training_ds, validation_ds, validation_raw, ckpt_path = load_pickles(model_dir)
                    tft = build_and_load_model(training_ds, ckpt_path, device=device_opt)
                    val_dl = validation_ds.to_dataloader(train=False, batch_size=min(batch_size, 32), num_workers=0)
                    st.info("ุฏุฑ ุญุงู ูุญุงุณุจู raw predictions...")
                    raw_predictions, x, *_ = tft.predict(val_dl, mode="raw", return_x=True)
                    st.info("ุฏุฑ ุญุงู ุชูุณุฑ ูุชุงุฌ...")
                    interpretation = tft.interpret_output(raw_predictions, reduction="mean")
                    st.success("ูุญุงุณุจู ุงููุช ูฺฺฏโูุง ฺฉุงูู ุดุฏ!")
                    st.write("**ฺฉูุฏูุง ููุฌูุฏ ุฏุฑ interpretation:**")
                    st.write(list(interpretation.keys()))
                    if "attention" in interpretation:
                        st.subheader("ููุดู ุชูุฌู (Attention Map)")
                        attention = interpretation["attention"]
                        st.write(f"ุดฺฉู attention: {attention.shape}")
                    if hasattr(tft, 'encoder_variables') and hasattr(tft, 'decoder_variables'):
                        st.subheader("ูฺฺฏโูุง ูุฏู")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write("**Encoder Variables:**")
                            st.write(tft.encoder_variables)
                        with col2:
                            st.write("**Decoder Variables:**")
                            st.write(tft.decoder_variables)
                    available_keys = [k for k in interpretation.keys() if 'importance' in k.lower()]
                    if not available_keys:
                        st.warning("ูฺ ุงุทูุงุนุงุช ุงููุช ูฺฺฏ ุงูุช ูุดุฏ ุฏุฑ ุฑูุด ฺฉูุงุณฺฉ.")
                        st.info("ูุทูุง ุงุฒ ุฑูุด Permutation ุงุณุชูุงุฏู ฺฉูุฏ.")
                except Exception as e:
                    st.error(f"ุฎุทุง ุฏุฑ ูุญุงุณุจู ุงููุช ูฺฺฏโูุง: {str(e)}")
                    st.exception(e)

    with tab2:
        st.markdown("### ุฑูุด Permutation Importance")
        col1, col2 = st.columns(2)
        with col1:
            n_repeats = st.slider("ุชุนุฏุงุฏ ุชฺฉุฑุงุฑ ุจุฑุง ูุฑ ูฺฺฏ", min_value=1, max_value=10, value=3, help="ุชุนุฏุงุฏ ุจุดุชุฑ = ูุชุฌู ุฏููโุชุฑ ุงูุง ุฒูุงู ุจุดุชุฑ")
        with col2:
            use_sample = st.checkbox("ุงุณุชูุงุฏู ุงุฒ ููููู ฺฉูฺฺฉ", value=True, help="ุจุฑุง ุณุฑุนุช ุจุดุชุฑุ ููุท ูุณูุช ุงุฒ ุฏุงุฏูโูุง ุงุณุชูุงุฏู ุดูุฏ")

        if st.button("ูุญุงุณุจู ุงููุช ูฺฺฏโูุง (Permutation Method)"):
            with st.spinner("ุฏุฑ ุญุงู ูุญุงุณุจู ุงููุช ูฺฺฏโูุง ุจุง ุฑูุด Permutation..."):
                try:
                    training_ds, validation_ds, validation_raw, ckpt_path = load_pickles(model_dir)
                    tft = build_and_load_model(training_ds, ckpt_path, device=device_opt)
                    if use_sample:
                        st.info(f"ุงุณุชูุงุฏู ุงุฒ batch size ฺฉูฺฺฉ ุจุฑุง ุชุณุฑุน ูุญุงุณุจุงุช...")
                    importance_scores = calculate_permutation_importance(tft, validation_ds, device=device_opt, n_repeats=n_repeats)
                    if importance_scores:
                        df_importance = pd.DataFrame([{"feature": feature, "importance": score} for feature, score in importance_scores.items()]).sort_values("importance", ascending=False)
                        st.success("ูุญุงุณุจู ุงููุช ูฺฺฏโูุง ุจุง ุฑูุด Permutation ฺฉุงูู ุดุฏ!")
                        st.subheader("๐ฏ ุงููุช ูฺฺฏโูุง (Permutation Importance)")
                        st.dataframe(df_importance, use_container_width=True)
                        chart = alt.Chart(df_importance).mark_bar().encode(x=alt.X("importance:Q", title="ุงููุช (ุงูุฒุงุด MSE)"), y=alt.Y("feature:N", sort="-x", title="ูฺฺฏ"), color=alt.Color("importance:Q", scale=alt.Scale(scheme="viridis")), tooltip=["feature:N", "importance:Q"]).properties(width=800, height=400, title="ุงููุช ูฺฺฏโูุง ุจุฑ ุงุณุงุณ ุฑูุด Permutation")
                        st.altair_chart(chart, use_container_width=True)
                        st.markdown("### ๐ ุชูุณุฑ ูุชุงุฌ:")
                        top_features = df_importance.head(3)
                        st.markdown("**๐ ูููโุชุฑู ูฺฺฏโูุง:**")
                        for idx, row in top_features.iterrows():
                            feature = row['feature']
                            importance = row['importance']
                            if importance > 0:
                                st.markdown(f"- **{feature}**: ุงูุฒุงุด {importance:.4f} ุฏุฑ MSE (ูฺฺฏ ููู)")
                            else:
                                st.markdown(f"- **{feature}**: ฺฉุงูุด {abs(importance):.4f} ุฏุฑ MSE (ููฺฉู ุงุณุช noise ุจุงุดุฏ)")
                        with st.expander("๐ก ุฑุงูููุง ุชูุณุฑ ูุชุงุฌ"):
                            st.markdown("""
                            **ูุญูู ุชูุณุฑ Permutation Importance:**
                            - **ููุฏุงุฑ ูุซุจุช**: ุจุง ุชุบุฑ ุชุตุงุฏู ุงู ูฺฺฏุ ุฏูุช ูุฏู ฺฉุงูุด ูโุงุจุฏ โ ูฺฺฏ ููู ุงุณุช
                            - **ููุฏุงุฑ ููู**: ุจุง ุชุบุฑ ุชุตุงุฏู ุงู ูฺฺฏุ ุฏูุช ูุฏู ุจูุชุฑ ูโุดูุฏ โ ููฺฉู ุงุณุช ูฺฺฏ noise ุง ุบุฑููู ุจุงุดุฏ
                            - **ููุฏุงุฑ ูุฒุฏฺฉ ุตูุฑ**: ูฺฺฏ ุชุงุซุฑ ฺูุฏุงู ุจุฑ ูุฏู ูุฏุงุฑุฏ
                            **ูฺฺฏโูุง ูุนูููุงู ููู ุฏุฑ ูพุดโุจู ูุฑูุด:**
                            - `daily_sales`: ููุฏุงุฑ ูุฑูุด ูุจู (target)
                            - `sales_lag_7`, `sales_lag_30`: ูุฑูุด ุจุง ุชุงุฎุฑ
                            - `sales_ma_7`, `sales_ma_30`: ูุงูฺฏู ูุชุญุฑฺฉ ูุฑูุด
                            - `day_of_week`: ุฑูุฒ ููุชู
                            - `promotion_active`: ูุถุนุช ุชุฎูู
                            """)
                        st.download_button(label="๐ฅ ุฏุงูููุฏ ูุชุงุฌ (CSV)", data=df_importance.to_csv(index=False).encode('utf-8'), file_name=f"feature_importance_permutation_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv", mime="text/csv")
                    else:
                        st.error("ูุญุงุณุจู ุงููุช ูฺฺฏโูุง ุงูุฌุงู ูุดุฏ!")
                except Exception as e:
                    st.error(f"ุฎุทุง ุฏุฑ ูุญุงุณุจู Permutation Importance: {str(e)}")
                    st.exception(e)
                    with st.expander("๐ง ุฑุงูููุง ุฑูุน ูุดฺฉู"):
                        st.markdown("""
                        **ูุดฺฉูุงุช ุงุญุชูุงู ู ุฑุงู ุญู:**
                        1. **ฺฉูุจูุฏ ุญุงูุธู**: 
                           - ุชุนุฏุงุฏ ุชฺฉุฑุงุฑ ุฑุง ฺฉู ฺฉูุฏ
                           - ฺฏุฒูู "ุงุณุชูุงุฏู ุงุฒ ููููู ฺฉูฺฺฉ" ุฑุง ูุนุงู ฺฉูุฏ
                           - batch size ุฑุง ฺฉุงูุด ุฏูุฏ
                        2. **ูุดฺฉู ุฏุฑ ุณุงุฎุชุงุฑ batch**:
                           - ููฺฉู ุงุณุช ูุงุฒ ุจู ุชุทุจู ฺฉุฏ ุจุง ุณุงุฎุชุงุฑ ุฎุงุต ูุฏู ุดูุง ุจุงุดุฏ
                           - ุจุฑุฑุณ ฺฉูุฏ ฺฉู ุขุง ูุงู ูฺฺฏโูุง ุฏุฑุณุช ุงุณุช
                        3. **ุฒูุงู ุฒุงุฏ ูุญุงุณุจู**:
                           - ุชุนุฏุงุฏ ุชฺฉุฑุงุฑ ุฑุง ุจู 1 ุง 2 ฺฉุงูุด ุฏูุฏ
                           - ุงุฒ ููููู ฺฉูฺฺฉโุชุฑ ุงุณุชูุงุฏู ฺฉูุฏ
                        """)

st.success("ูพุงุงู.")

# -----------------------------
# Usage help when not loaded
# -----------------------------
if not st.session_state.data_loaded:
    st.info("ุจุฑุง ุดุฑูุนุ ุฑู ุฏฺฉูู 'ุจุงุฑฺฏุฐุงุฑ ูุฏู ู ุงุฌุฑุง' ฺฉูฺฉ ฺฉูุฏ.")
    with st.expander("ุฑุงูููุง ุงุณุชูุงุฏู"):
        st.markdown("""
        ### ูุญูู ุงุณุชูุงุฏู:
        1. ูุณุฑ ูพูุดู ูุฏู ุฑุง ุฏุฑ ููุงุฑ ฺฉูุงุฑ ุชูุธู ฺฉูุฏ
        2. ุชูุธูุงุช ููุฑุฏ ูุธุฑ (deviceุ batch size) ุฑุง ุงูุชุฎุงุจ ฺฉูุฏ  
        3. ููุน ููุงุด ุฑุง ุงูุชุฎุงุจ ฺฉูุฏ:
           - **ุชุฌูุน**: ููุงุด ูุฌููุน ูุฑูุด ููู ูุฑูุดฺฏุงูโูุง
           - **ูุฑูุดฺฏุงู ุฎุงุต**: ููุงุด ูุฑูุด ฺฉ ูุฑูุดฺฏุงู ุฎุงุต
        4. ุฑู ุฏฺฉูู "ุจุงุฑฺฏุฐุงุฑ ูุฏู ู ุงุฌุฑุง" ฺฉูฺฉ ฺฉูุฏ
        5. ุจุฑุง ูุญุงุณุจู ุงููุช ูฺฺฏโูุงุ ุงุฒ ุชุจโูุง "ุงููุช ูฺฺฏโูุง" ุงุณุชูุงุฏู ฺฉูุฏ
        """)
        st.markdown("---")
        st.markdown("""
        ### ุฏุฑุจุงุฑู ุฑูุดโูุง Feature Importance:
        **1. ุฑูุด ฺฉูุงุณฺฉ TFT:**
        - ุงุฒ attention mechanism ูุฏู ุงุณุชูุงุฏู ูโฺฉูุฏ
        - ูุชุงุฌ ุณุฑุนโุชุฑ ุงูุง ูุญุฏูุฏ ุจู ุณุงุฎุชุงุฑ ูุฏู
        - ููฺฉู ุงุณุช ููุดู ฺฉุงุฑ ูฺฉูุฏ
        **2. ุฑูุด Permutation:**
        - ูุณุชูู ุงุฒ ููุน ูุฏู
        - ุงูุฏุงุฒูโฺฏุฑ ุชุงุซุฑ ูุงูุน ูุฑ ูฺฺฏ
        - ุฒูุงูโุจุฑ ุงูุง ุฏููโุชุฑ ู ูุงุจูโุงุนุชูุงุฏุชุฑ
        - ุจุง ูุฑ ููุน ูุฏู ML ุณุงุฒฺฏุงุฑ ุงุณุช
        """)
